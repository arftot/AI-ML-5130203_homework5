{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "459463e6-0d6b-4173-8831-4661e857c320",
   "metadata": {},
   "source": [
    "# MULTILAYER PERCEPTRON MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884c6a63-4e5f-44b0-95bf-87d543bb4274",
   "metadata": {},
   "source": [
    "## 1) Implementation of Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "251a9838-52d3-4a1a-a6c5-c0d57bdd706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8576dba1-8a86-4a5d-a310-e85cf200cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for Multilayer Perceptron\n",
    "class MLPAlgorithm(object):\n",
    "\n",
    "    # hyperparameters definition\n",
    "    def __init__(self, eta, threshold, max_epochs):\n",
    "        self.eta = eta\n",
    "        self.threshold = threshold\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "    # function to define MLP architecture\n",
    "    def build_architecture(self, input_length, hidden_length, output_length):\n",
    "        # hyperparameters for MLP architecture\n",
    "        self.input_length = input_length\n",
    "        self.hidden_length = hidden_length\n",
    "        self.output_length = output_length\n",
    "\n",
    "        # random initialization of weights and biases\n",
    "        # hidden layer [b x (a+1)]\n",
    "        self.Wh = np.random.rand(self.hidden_length, self.input_length)\n",
    "        self.bh = np.random.rand(self.hidden_length)\n",
    "        # output layer [c x (b+1)]\n",
    "        self.Wo = np.random.rand(self.output_length, self.hidden_length)\n",
    "        self.bo = np.random.rand(self.output_length)\n",
    "\n",
    "        return self\n",
    "\n",
    "    # linear combination\n",
    "    def input_net(self, x, w, b):\n",
    "        net = np.dot(w, x) + b\n",
    "        return net\n",
    "\n",
    "    # sigmoid activation function\n",
    "    def f(self, net):\n",
    "        return 1/(1 + math.exp(-net))\n",
    "\n",
    "    # derivate of sigmoid activation function\n",
    "    def df(self, fnet):\n",
    "        return fnet * (1 - fnet)\n",
    "\n",
    "    # forward step\n",
    "    def forward(self, x):\n",
    "        # hidden layer\n",
    "        self.net_h = self.input_net(x, self.Wh, self.bh)\n",
    "        self.fnet_h = np.array([self.f(net) for net in self.net_h])\n",
    "        self.dfnet_h = np.array([self.df(fnet) for fnet in self.fnet_h])\n",
    "\n",
    "        # output layer\n",
    "        self.net_o = self.input_net(self.fnet_h, self.Wo, self.bo)\n",
    "        self.fnet_o = np.array([self.f(net) for net in self.net_o])\n",
    "        self.dfnet_o = np.array([self.df(fnet) for fnet in self.fnet_o])\n",
    "\n",
    "    # function to make prediction given a point\n",
    "    def predict(self, xi):\n",
    "        self.forward(xi)\n",
    "        logits = self.fnet_o\n",
    "\n",
    "        if self.output_length == 1:\n",
    "            pred = np.where(self.fnet_o >= 0.5, 1, 0)[0]\n",
    "        else:\n",
    "            pred = np.argmax(self.fnet_o)[0]\n",
    "\n",
    "        return logits, pred\n",
    "\n",
    "    # iterative training step\n",
    "    def fit(self, x_train, y_train):\n",
    "        n = x_train.shape[0]\n",
    "        E = 2 * self.threshold\n",
    "        count = 0\n",
    "        cost = list()\n",
    "\n",
    "        # training in each epoch\n",
    "        while(E >= self.threshold and count <= self.max_epochs + 1):\n",
    "            E = 0\n",
    "\n",
    "            # stochastic gradient descendent algorithm (SGD) -> for each sample\n",
    "            for i in range(n):\n",
    "                xi = x_train[i, :]\n",
    "\n",
    "                if self.output_length > 1:  # for multi-classification problems\n",
    "                    yi = y_train[i, :]\n",
    "                else:                        # for binary-classification problems\n",
    "                    yi = y_train[i]\n",
    "\n",
    "                self.forward(xi)\n",
    "                y_pred = self.fnet_o\n",
    "\n",
    "                # calculate error\n",
    "                error = (yi - y_pred)\n",
    "                E = E + sum(error**2)\n",
    "\n",
    "                #Output Layer\n",
    "                #------------#\n",
    "\n",
    "                # initialize gradient weights Wo for output layer\n",
    "                dE_dWo = np.zeros(\n",
    "                        self.output_length * self.hidden_length).reshape(\n",
    "                                self.output_length, self.hidden_length)\n",
    "\n",
    "                # initialize gradient bias bo for output layer\n",
    "                dE_dbo = np.zeros(self.output_length)\n",
    "\n",
    "                # calculate delta for output layer\n",
    "                delta_o = -error * self.dfnet_o\n",
    "\n",
    "                # iterate for each neuron in output layer\n",
    "                for j in range(self.output_length):\n",
    "                    # iterate in each sinapsis related with j-th output neuron\n",
    "                    for i in range(self.hidden_length):\n",
    "                        # dE_dWo\n",
    "                        dE_dWo[j, i] = delta_o[j] * self.fnet_h[i]\n",
    "                        self.Wo[j, i] = self.Wo[j, i] - self.eta * dE_dWo[j, i]\n",
    "                    # dE_dbo\n",
    "                    dE_dbo[j] = delta_o[j] * 1\n",
    "                    self.bo[j] = self.bo[j] - self.eta * dE_dbo[j]\n",
    "\n",
    "                #Hidden Layer\n",
    "                #------------#\n",
    "\n",
    "                # initialize gradient weights Wh for hidden layers\n",
    "                dE_dWh = np.zeros(\n",
    "                        self.hidden_length * self.input_length).reshape(\n",
    "                                self.hidden_length, self.input_length)\n",
    "\n",
    "                # initialize gradient biases bh for hidden layers\n",
    "                dE_dbh = np.zeros(self.hidden_length)\n",
    "\n",
    "                # calculate delta for hidden layer\n",
    "                delta_h = self.dfnet_h * np.dot(delta_o, self.Wo)\n",
    "\n",
    "                # iterate for each neuron of hidden layers\n",
    "                for i in range(self.hidden_length):\n",
    "                    # iterate in each sinapsis related with i-th hidden neuron\n",
    "                    for k in range(self.input_length):\n",
    "                        #dE_dWh\n",
    "                        dE_dWh[i, k] = delta_h[i] * xi[k]\n",
    "                        self.Wh[i, k] = self.Wh[i, k] - self.eta * dE_dWh[i, k]\n",
    "                    #dE_dbh\n",
    "                    dE_dbh[i] = delta_h[i] * 1\n",
    "                    self.bh[i] = self.bh[i] - self.eta * dE_dbh[i]\n",
    "\n",
    "            # count number of epochs\n",
    "            count = count + 1\n",
    "\n",
    "            # calculate mean square error (MSE)\n",
    "            E = round(1/2 * (E/n), 5)\n",
    "            cost.append(E)\n",
    "\n",
    "            # report results each 100 epochs\n",
    "            if(count%100 == 0):\n",
    "                print('Epoch ', count, ': loss = ', E)\n",
    "\n",
    "        # store results in MLP class\n",
    "        self.epochs = count\n",
    "        self.loss_ = E\n",
    "        self.cost_ = cost\n",
    "\n",
    "        return self\n",
    "\n",
    "    # function to make iterative process of test\n",
    "    def test(self, x_test, y_test):\n",
    "        n = x_test.shape[0]\n",
    "        self.accuracy = 0\n",
    "        y_prob = list()\n",
    "        y_pred = list()\n",
    "\n",
    "        for i in range(n):\n",
    "            xi = x_test[i, :]\n",
    "\n",
    "            if self.output_length > 1:  # for multi-classification problems\n",
    "                yi = y_test[i, :]\n",
    "            else:                       # for binary classification problems\n",
    "                yi = y_test[i]\n",
    "\n",
    "            # given inputs, predict class and probabilities\n",
    "            logits, pred = self.predict(xi)\n",
    "            y_prob.append(logits)\n",
    "            y_pred.append(pred)\n",
    "\n",
    "            # verify correct classifications\n",
    "            if np.array_equal(y_pred[i], yi):\n",
    "                self.accuracy += 1\n",
    "\n",
    "        # calculate accuracy\n",
    "        self.accuracy = 100 * round(self.accuracy/n, 5)\n",
    "\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557cc379-9204-422b-ad24-107ea1046a89",
   "metadata": {},
   "source": [
    "## 2) Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "66b6f005-b4ab-4d9e-bea8-b37dbba126df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.051354</td>\n",
       "      <td>-3.340075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.772868</td>\n",
       "      <td>0.794436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.479800</td>\n",
       "      <td>-1.924788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.766882</td>\n",
       "      <td>-4.799878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.220152</td>\n",
       "      <td>1.191662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2  class\n",
       "0  3.051354 -3.340075      1\n",
       "1  1.772868  0.794436      0\n",
       "2 -0.479800 -1.924788      0\n",
       "3  1.766882 -4.799878      1\n",
       "4  5.220152  1.191662      1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = pd.read_csv(\"datasets/nonlinearly_separable_data.csv\", header = 0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "65f46f64-fbe0-4194-bf75-491dc576e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split independent and dependent variables\n",
    "x = dataset.iloc[:800, :2].values\n",
    "y = dataset.iloc[:800, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8a5be8e8-2467-4241-8cb0-7a804a6a58db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.05135376, -3.34007463],\n",
       "       [ 1.77286801,  0.79443613],\n",
       "       [-0.4797995 , -1.92478783],\n",
       "       [ 1.76688225, -4.79987761],\n",
       "       [ 5.22015234,  1.1916615 ]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "63613460-2119-4583-8d4d-26b8a2a510d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a38d35-947b-49e9-8781-fbda557c2859",
   "metadata": {},
   "source": [
    "## 3) Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "31e68598-ec7b-41c8-9e24-9ddd1a943699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MLPAlgorithm at 0x177a5980990>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training process\n",
    "model = MLPAlgorithm(eta = 0.01, max_epochs = 1000, threshold = 1e-4)\n",
    "model.build_architecture(input_length = 2, hidden_length = 2, output_length = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9c89d427-87bc-4a22-ab2a-008325e69a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  100 : loss =  0.07183\n",
      "Epoch  200 : loss =  0.06651\n",
      "Epoch  300 : loss =  0.0654\n",
      "Epoch  400 : loss =  0.06488\n",
      "Epoch  500 : loss =  0.06457\n",
      "Epoch  600 : loss =  0.06436\n",
      "Epoch  700 : loss =  0.0642\n",
      "Epoch  800 : loss =  0.06408\n",
      "Epoch  900 : loss =  0.06399\n",
      "Epoch  1000 : loss =  0.06391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.MLPAlgorithm at 0x177a5980990>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training step\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623f8472-470e-4f50-88e6-8e80909de209",
   "metadata": {},
   "source": [
    "## 4) Testing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "12136f4d-c20c-467a-a980-6a35a313e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t = dataset.iloc[801:1000, :2].values\n",
    "y_t = dataset.iloc[801:1000, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ee551bd3-036b-4ec5-80dc-b5c4ca27eb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  79.899 %\n"
     ]
    }
   ],
   "source": [
    "# make test\n",
    "model.test(x_t, y_t)\n",
    "print(\"Accuracy = \", model.accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05685bb7-8d78-4737-bcd5-5d3b735d6719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
